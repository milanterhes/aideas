import { useIdeaService } from '@/lib/idea-service-provider'
import { useQueryClient } from '@tanstack/react-query'
import OpenAI from 'openai'
import { useMemo, useState } from 'react'
import { ideaQuery, addRawIdeasMutation } from './local-ideas'
import { toast } from 'sonner'

const systemPrompt = `
    You are a helpful assistant that generates ideas for the user. If they ask you for something else, you can tell me that you can only generate ideas. Use markdown to format your responses.

    After generating ideas, ask the user if they would like to save the ideas. If they say yes, you can save the ideas for them.
`

const useChat = (apiKey: string) => {
    const queryClient = useQueryClient()
    const ideaService = useIdeaService(state => state.service)
    const aiClient = useMemo(() => new OpenAI({
        apiKey,
        dangerouslyAllowBrowser: true,
    }), [apiKey])

    const setIdeas = addRawIdeasMutation.useMutation(ideaService, {
        onSuccess: () => {
            queryClient.invalidateQueries({
                exact: true,
                queryKey: ideaQuery.queryKey,
            })
        },
        onError: (error) => {
            console.log(error)
            toast.error('Failed to save ideas: ' + error.message)
        }
    })

    function handleToolCall(toolCall: ToolCall): OpenAI.Chat.Completions.ChatCompletionMessageParam[] {
        if (toolCall.name === 'save_ideas') {
            setIdeas.mutate(toolCall.arguments);
            return [{
                role: 'assistant',
                content: 'I saved the ideas for you.',
            }];
        }
        return [];
    }

    const [isStreaming, setIsStreaming] = useState(false)
    const [streamingMessage, setStreamingMessage] = useState<string | null>(null)

    const [messages, setMessages] = useState<OpenAI.Chat.Completions.ChatCompletionMessageParam[]>([
        {
            role: 'system',
            content: systemPrompt,
        },
        // {
        //     role: 'user',
        //     content: 'I am planning on buying a yacht. can you give me name ideas?',
        // },
        // {
        //     role: 'assistant',
        //     content: 'Sure! Here are some name ideas for your yacht:\n - The Sea Queen\n - The Blue Horizon\n - The Ocean Dream\n - The Sea Breeze\n - The Aqua Star\nWould you like to save these ideas?',
        // }
    ])

    const sendPrompt = async (prompt: string) => {
        try {
            setIsStreaming(true);
            const stream = await aiClient.chat.completions.create({
                model: 'gpt-4o',
                messages: [
                    ...messages,
                    {
                        role: 'user',
                        content: prompt,
                    }
                ],
                stream: true,
                tools: [{
                    type: 'function',
                    function: {
                        name: 'save_ideas',
                        description: 'Save the ideas generated by the assistant',
                        parameters: {
                            type: 'object',
                            properties: {
                                ideas: {
                                    type: 'array',
                                    items: {
                                        type: 'object',
                                        properties: {
                                            idea: {
                                                type: 'string',
                                                description: 'The idea generated by the assistant',
                                            },
                                            context: {
                                                type: 'string',
                                                description: 'A description of the context in which the idea was generated',
                                            },
                                        },
                                    },
                                },
                            },
                        },
                    }
                }]
            });

            setMessages(prev => [...prev, {
                role: "user",
                content: prompt,
            }]);

            let content: null | string = null;
            let toolCall: ToolCall | null = null;

            for await (const chunk of stream) {
                const { nextContent, nextToolsCalls } = handleChunk({ chunk, content: content, toolCall });
                if (nextContent) {
                    content = nextContent;
                    setStreamingMessage(content);
                }
                toolCall = nextToolsCalls;
            }

            if (content) {
                setMessages(prev => [...prev, {
                    role: "assistant",
                    content: content,
                }]);
            }
            if (toolCall) {
                const toolMessages = handleToolCall(toolCall);
                setMessages(prev => [...prev, ...toolMessages]);
            }
        } catch (error) {
            console.log(error);
        } finally {
            setIsStreaming(false);
            setStreamingMessage('');
        }
    };

    return { aiClient, sendPrompt, isStreaming, streamingMessage, messages }
}

type ToolCall = { arguments: string, name: string }

/**
 * Format the content of the chat message. It will return null if both the old and new content are null.
 * @param old The old content of the chat message.
 * @param newContent The new content of the chat message.
 */
function formatContent(old: string | null, newContent: string | null): string | null {
    if (old === null && newContent === null) {
        return null;
    }
    return `${old ?? ""}${newContent ?? ""}`;
}

const handleChunk = ({ chunk, content, toolCall }: { chunk: OpenAI.Chat.Completions.ChatCompletionChunk, content: string | null, toolCall: ToolCall | null }) => {
    const nextContent = formatContent(content, chunk.choices[0].delta?.content ?? null);

    const nextToolsCalls: ToolCall = toolCall ? { ...toolCall } : { arguments: '', name: '' };

    if (chunk.choices[0].delta?.tool_calls) {
        chunk.choices[0].delta.tool_calls.forEach((toolCall) => {
            if (toolCall.function?.name) {
                nextToolsCalls.name = toolCall.function.name;
            }
            if (toolCall.function?.arguments) {
                nextToolsCalls.arguments += toolCall.function.arguments ?? '';
            }
        });
    }

    return { nextContent, nextToolsCalls: nextToolsCalls };
}

export default useChat